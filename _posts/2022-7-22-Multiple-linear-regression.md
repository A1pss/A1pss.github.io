---
title: 第七讲：多元线性回归分析
layout: post
post-image: "https://alps-images.obs.cn-east-2.myhuaweicloud.com/img/image-20230722185917433.png"
description: 数学建模算法笔记
tags:
- mathematics modeling
- knowledge
---


> **声明：**
>
> 笔记为本人个人整理，参考清风大佬的视频课件，若有错误请指出。


回归分析的任务就是，通过研究自变量X和因变量Y的相关关系，尝试去解释Y的形成机制，进而达到通过X去预测Y的目的。

---

## 引入

1. 回归分析与相关分析的区别

   回归分析是以Y为研究对象，研究X对Y的影响，主次次序不可颠倒，可用于预测；

   相关分析是研究X与Y的关系，没有主次之分，不可用于预测。

2. 因变量种类

   - 经济学家研究经济增长的决定因素，那么Y可以选取GDP增长率（连续数值型变量）
   - P2P公司要研究借款人是否能按时还款，那么Y可以设计成一个二值变量，Y=0时代表可以还款，Y=1时代表不能还款（0‐1型变量）
   - 消费者调查得到的数据（1表示非常不喜欢，2表示有点不喜欢，3表示一般般，4表示有点喜欢，5表示非常喜欢）（定序变量）
   - 管理学中RFM模型：F代表一定时间内，客户到访的次数，次数其实就是一个非负的整数。（计数变量）
   - 研究产品寿命、企业寿命甚至是人的寿命（这种数据往往不能精确的观测，例如现在要研究吸烟对于寿命的影响，如果选取的样本中老王60岁，现在还活的非常好，我们不可能等到他去世了再做研究，那怎么办呢？直接记他的寿命为60+，那这种数据就是截断的数据）（生存变量）

3. 回归分析的目的

   1. 识别重要变量（逐步回归法）

      哪些X变量是同Y真的相关，哪些不是。

   2. 判断相关性的方向

      这些有用的X变量同Y的相关关系是正的呢，还是负的？

   3. 估计权重（回归系数）

      赋予不同X不同的权重，也就是不同的回归系数，进而我们可以知道不同变量之间的相对重要性。

4. 回归分析的分类

   | 类型     | 模型                | Y的特点             | 例子               |
   | -------- | ------------------- | ------------------- | ------------------ |
   | 线性回归 | OLS、GLS (最小二乘) | 连续数值型变量      | GDP、产量、收入    |
   | 0-1回归  | logistic回归        | 二值变量 (0-1)      | 是否违约、是否得病 |
   | 定序回归 | probit定序回归      | 定序变量            | 每分钟车流量       |
   | 计数回归 | 泊松回归 (泊松分布) | 计数变量            | 每分钟车流量       |
   | 生存回归 | Cox等比例风险回归   | 生存变量 (截断数据) | 企业、产品的寿命   |

5. 数据的分类

   - 横断面数据 (Cross Sectional Data)：在某一时点收集的不同对象的数据。

     <img src="https://alps-images.obs.cn-east-2.myhuaweicloud.com/img/image-20230722143737594.png" alt="image-20230722143737594" style="zoom:33%;" />

   - 时间序列数据 (Tima Series Data)：同一对象在不容时间连续观察所得的数据

     <img src="https://alps-images.obs.cn-east-2.myhuaweicloud.com/img/image-20230722143749291.png" alt="image-20230722143749291" style="zoom:33%;" />

   - 面板数据 (Panel Data)：横截面数据与时间序列数据综合起来的一种数据资源。例如：2010-2020年，我国个省份GDP的数据。
   
6. 不同数据类型的处理方法

   | 数据类型     | 常见建模方法                                |
   | ------------ | ------------------------------------------- |
   | 横截面数据   | 多元线性回归                                |
   | 时间序列数据 | 移动平均、指数平滑、ARIMA、GARCH、VAR、协积 |
   | 面板数据     | 固定效应和随机效应、静态面板和动态面板      |

## *数据的收集

[简道云汇总](https://link.jiandaoyun.com/f/5cc652cc2cf3b22fb7819189)  110+数据网站

[虫部落数据搜索](http://data.chongbuluo.com/【汇总】数据来源/大数据平台)

[汇总](https://link.jiandaoyun.com/f/5b35d05ff7f6ef2604d39a93)  数据来源/大数据平台

[大数据工具导航工具](http://hao.199it.com/数据平台)

[数据平台](http://www.hippter.com/data.html)

上面的数据多半都是宏观数据，微观数据市面上很少大家可以在人大经济论坛搜索：[经管之家](https://bbs.pinggu.org/)

## 线性回归模型

1. 一元线性回归模型(多元就是一个以上自变量，其他不变)

   假设y是因变量，x是自变量，且满足如下线性关系：
   

![](https://www.zhihu.com/equation?tex=%0A%20%20%20y_i%3D%5Cbeta_0%2B%5Cbeta_1x_1%2B%5Cmu_i%0A%20%20%20)

   ![](https://www.zhihu.com/equation?tex=%5Cbeta_0)和![](https://www.zhihu.com/equation?tex=%5Cbeta_1)为回归系数，![](https://www.zhihu.com/equation?tex=%5Cmu_1)为无法观测的且满足一定条件的扰动项

   令预测值

![](https://www.zhihu.com/equation?tex=%0A%20%20%20%5Chat%7By_i%7D%3D%5Chat%7B%5Cbeta_0%7D%2B%5Chat%7B%5Cbeta_1%7Dx_1%0A%20%20%20)

   我们称![](https://www.zhihu.com/equation?tex=%5Chat%7B%5Cmu_i%7D%3Dy_i-%5Chat%7By_i%7D)为残差

   > 线性假定并不要求初始模型都呈上述的严格线性关系，自变量与因变量可通过变量替换而转化成线性模型(以下模型都是线性模型)
   > 
![](https://www.zhihu.com/equation?tex=%0A%20%20%20%3E%20y_i%3D%5Cbeta_0%2B%5Cbeta_1%5Cln%7Bx_i%7D%2B%5Cmu_i%20%5C%5C%20%5Cln%7By_i%7D%3D%5Cbeta_0%2B%5Cbeta_1%5Cln%7Bx_i%7D%2B%5Cmu_i%20%5C%5C%20y_i%3D%5Cbeta_0%2B%5Cbeta_1x_1%2B%5Cbeta_2x_i%5E2%2B%5Cmu_i%20%5C%5C%20y_i%3D%5Cbeta_0%2B%5Cbeta_1x_%7B1i%7D%2B%5Cbeta_2x_%7B2i%7D%2B%5Cdelta%20x_%7B1i%7Dx_%7B2i%7D%2B%5Cmu_i%0A%20%20%20%3E%20)

   > 这种数据预处理用Excel(推荐)、MATLAB、STATA等软件都可以

## 自变量的选取

1. 内生性与外生性

   - 内生性：遗漏变量对回归系数的影响非常大，称该回归模型具有内生性

   - 外生性：假设模型为：![](https://www.zhihu.com/equation?tex=y%3D%5Cbeta_0%2B%5Cbeta_1x_1%2B%5Cbeta_2x_2%2B%5Ccdots%2B%5Cbeta_kx_k%2B%5Cmu)，![](https://www.zhihu.com/equation?tex=%5Cmu)为无法观测的且满足一定条件的扰动项(误差项)。如果满足![](https://www.zhihu.com/equation?tex=%5Cmu)与所有的自变量都不相关，则该模型具有外生性

2. 核心解释变量和控制变量
   - 核心解释变量：我们最感兴趣的变量，因此我们特别希望得到对其系数的一致估计。
   - 控制变量：我们可能对于这些变量本身并无太大兴趣；而之所以把它们也放入回归方程，主要是为了 “控制住” 那些对因变量有影响的遗漏因素。
   - 在实际应用中，我们只要保证核心解释变量与![](https://www.zhihu.com/equation?tex=%5Cmu)不相关即可。
   
3. 虚拟变量(重要)

   对于自变量中的定性变量，例如性别、地域等，在回归中需要通过虚拟变量处理(也就是STATA中`tabulate 变量名,gen(A)`中的A)

   **为了避免完全多重共线性的影响，引入虚拟变量的个数一般是分类数减1**

4. 含有交互项的自变量

   price:房价  sqrft:住房面积  bdrms:卧室数量  bthrms:卫生间数量

   ![image-20230722143810125](https://alps-images.obs.cn-east-2.myhuaweicloud.com/img/image-20230722143810125.png)

## 回归系数的解释

- 回归系数的解释
  

![](https://www.zhihu.com/equation?tex=%0A%20%20y_i%3D%5Cbeta_0%2B%5Cbeta_1x_%7B1i%7D%2B%5Cbeta_2x_%7B2i%7D%2B%5Ccdots%2B%5Cbeta_kx_%7Bki%7D%2B%5Cmu_i%20%5C%5C%20%5CDownarrow%20%5C%5C%20%5Chat%7By_i%7D%3D%5Chat%7B%5Cbeta_0%7D%2B%5Chat%7B%5Cbeta_1%7Dx_%7B1i%7D%2B%5Chat%7B%5Cbeta_2%7Dx_%7B2i%7D%2B%5Ccdots%2B%5Chat%7B%5Cbeta_k%7Dx_%7Bki%7D%0A%20%20)

  ![](https://www.zhihu.com/equation?tex=%5Chat%7B%5Cbeta_0%7D)的意义一般不考虑，![](https://www.zhihu.com/equation?tex=%5Chat%7B%5Cbeta_m%7D%28m%3D1%2C2%2C%5Ccdots%2Ck%29)指控制其他自变量不变时。![](https://www.zhihu.com/equation?tex=x_m)每层加一个单位，对![](https://www.zhihu.com/equation?tex=y_i)造成的变化。

- 四种模型回归系数的解释

  1. 一元线性回归：𝑦 = 𝑎 + 𝑏𝑥 + 𝜇，x每增加1个单位，y平均变化b个单位
  2. 双对数模型：𝑙𝑛𝑦 = 𝑎 + 𝑏𝑙𝑛𝑥 + 𝜇，x每增加1%，y平均变化b%
  3. 半对数模型：𝑦 = 𝑎 + 𝑏𝑙𝑛𝑥 + 𝜇，x每增加1%，y平均变化b/100个单位
  4. 半对数模型：𝑙𝑛𝑦 = 𝑎 + 𝑏𝑥 + 𝜇，x每增加1个单位，y平均变化(100b)%
  
  > 什么时候取对数？
  >
  > 取对数意味着原被解释变量对解释变量的弹性为百分比的变化而不是数值的变化；目前，对于什么时候取对数还没有固定的规则，但是有一些经验法则：
  >
  > 1. 与市场价值相关的，例如，价格、销售额、工资等都可以取对数；
  > 2. 以年度量的变量，如受教育年限、工作经历等通常不取对数；
  > 3. 比例变量，如失业率、参与率等，两者均可；
  > 4. 变量取值必须是非负数，如果包含0，则可以对y取对数ln(1+y);
  >
  > 取对数的好处：（1）减弱数据的异方差性（2）如果变量本身不符合正态分布，取了对数后可能渐近服从正态分布（3）模型形式的需要，让模型具有经济学意义。

## STATA

### 基础操作

1. 文件-导入-Excel表格

   注意是否将第一行作为变量名

2. 代码记得保存为do文件

### 数据的描述性统计

#### 定量数据

`summarize 变量1 变量2 ... 变量n`

输出结果：

| Variable | Obs  | Mean | Std. Dev. |  Min   |  Max   |
| :------: | :--: | :--: | :-------: | :----: | :----: |
|  变量1   | 总数 | 均值 |  标准差   | 最小值 | 最大值 |

  #### 定性数据

`tabulate 变量名,gen(A)`

返回对应的这个变量的频率分布表，并生成对应的虚拟变量(A1,A2,...)

> 把生成的表格复制粘贴入Excel，去除不想要的部分，将剩余部分导入论文中
>
> STATA中菜单栏的数据编辑器(浏览)可以查看数据

#### Excel中数据透视表

插入-数据透视表

### STATA回归语句

- `regress y x1 x2 ... xk`

  (默认使用的OLS：普通最小二乘估计法)

- 生成表格如下:

  |   Source |        SS         |   df(自由度)    | MS(均值) |
  | -------: | :---------------: | :-------------: | :------: |
  |    Model |  SSR(回归平方和)  | k(自变量的个数) |          |
  | Residual |  SSE(误差平方和)  |   obs - k - 1   |          |
  |    Total | SST(总离差平方和) |     obs - 1     |          |

  Number of obs

  F(k, obs-k-1)  (联合显著性检验，原假设：![](https://www.zhihu.com/equation?tex=%5Cbeta_1%3D%5Ccdots%3D%5Cbeta_k%3D0))

  Prob > F  (Prob为P值，联合显著性检验，原假设：![](https://www.zhihu.com/equation?tex=%5Cbeta_1%3D%5Ccdots%3D%5Cbeta_k%3D0))

  R-squared

  Adj R squared  (即调整后的拟合优度，我们一般看这个数不看R方)

  Root MSE

  | y(因变量)           | Coef.(回归系数) | Std. Err.(回归系数的标准误差) | t    | P><img src="https://alps-images.obs.cn-east-2.myhuaweicloud.com/img/image-20230722194204258.png" alt="image-20230722194204258" style="zoom:70%;" /> | [95% Conf. Interval] |
  | ------------------- | --------------- | ----------------------------- | ---- | ------------------------------------------------------------ | -------------------- |
  | x1                  |                 |                               |      |                                                              |                      |
  | x2                  |                 |                               |      |                                                              |                      |
  | _cons(常数项，即β0) |                 |                               |      |                                                              |                      |
  
  上表中第五列P值最有用，其他不用看。P值小于0.05，表示在95%置信水平下，该回归系数显著的异于0。P值大于置信水平的项就不用看了。
  
- 在加入虚拟变量回归时，Stata会自动检测数据的完全多重共线性问题。

## 最终处理

### 拟合优度较低怎么办

1. 回归分为解释性回归和预测型回归

   预测型一般更看重拟合优度R方

   解释型回归更多关注模型整体显著性以及自变量的统计显著性和经济意义显著性。例如：探究哪个变量对解释对象影响最大。

2. 可以对模型进行调整，例如对数据取对数或者平方后再进行回归

3. 数据中可能有存在异常值或者数据的分布极度不均匀，调整后再进行回归

> 注：我们一般使用调整后的拟合优度Adj R squared
>
> 我们引入的自变量越多，拟合优度会变大。但我们倾向于使用调整后的拟合优度，如果新引入的自变量对SSE的减少程度特别少，那么调整后的拟合优度反而会减小。（这句话可以放入论文中作解释）
> 
![](https://www.zhihu.com/equation?tex=%0A%3E%20R_%7Badjusted%7D%5E2%3D1-%5Cfrac%7BSSE/%28n-k-1%29%7D%7BSST/%28n-1%29%7D%0A%3E%20)


### 标准化回归系数

- 求法：对数据进行标准化，就是将原始数据减去它的均数后，再除以该变量的标准差，计算得到新的变量值，新变量构成的回归方程称为标准化回归方程，回归后相应可得到标准化回归系数。
  
- 作用：用来说明自变量对应变量影响的大小。标准化回归系数的绝对值越大，说明对因变量的影响就越大 (还是只关注显著的回归系数)
  
- STATA标准化回归命令

  `regress y x1 x2 … xk,beta`

  生成的表格：只是最后加了一列标准化回归系数，其中常数项没有标准化回归系数。

## 注意的点

1. 在回归分析之前数据不要进行归一化处理，否则回归系数不好解释。

2. 在回归模型的解释部分，要写出求得的具体回归系数是多少(![](https://www.zhihu.com/equation?tex=%5Chat%7B%5Cbeta_0%2C%7D%5Chat%7B%5Cbeta_1%7D%2C%5Cdots))

   还要写出回归系数的显著性。

3. 回归系数的置信区间不要包括原点，包括原点说明可以等于0 (这点可以作为解释为何没模型不准确的原因)。

4. 如果是解释型模型不是预测型模型，拟合优度低也没关系，但不要因为拟合优度低就添加高次自变量。尽量不要设立高次模型，次方项我们不好解释为什么给它这个次方，怎么得出的给他这个次方。

5. 若要探究哪个变量对被解释量影响最大应该用标准化的回归系数。

## *用Excel进行数据预处理与画数据透视图

1. 数据预处理：

   选中区域 - 数据 - 数据分析 - 描述统计 - 输入区域，逐列，(标志位于第一行)，汇总统计，最大值，最小值都填上

2. 数据透视图：

   见第七讲第七部分







