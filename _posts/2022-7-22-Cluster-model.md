---
title: 第十讲：聚类模型
layout: post
post-image: "https://alps-images.obs.cn-east-2.myhuaweicloud.com/img/image-20230722185917433.png"
description: 数学建模算法笔记
tags:
- mathematics modeling
- knowledge
---


> **声明：**
>
> 笔记为本人个人整理，参考清风大佬的视频课件，若有错误请指出。


## 三类聚类算法如何选择

只有两个指标，且做出散点图后发现很“DNSCAN”，就是用DBSCAN算法；

其他情况下都建议用系统聚类。

K-means也可以用，只不过论文上能写的东西比较少

## K-means聚类算法

### 流程

1. 指定需要划分的簇的个数K值(类的个数)；
2. 随机选择K个数据对象作为初始的聚类中心(不一定是我们要的样品点)；
3. 计算其余各个数据对象到聚类中心的距离，把数据对象划归到距离他最近的那个中心所在的簇类中；
4. 调整新类并重新加算出新类的中心；
5. 循环步骤3，4，看中心是否收敛(不变)，收敛或达到迭代次数后停止循环。

注意1：K值怎么定主要取决于个人的经验与感觉，通常的做法是多尝试几个K值，看分成几类的结果更好解释，更符合分析目的等。

注意2：

### 优缺点

- 优点：

  算法简单、快速；

  对处理大数据集，该算法是相对高效率的。

- 缺点：

  要求用户必须事先给出要生成的簇的数目K；

  对初值敏感；

  对于孤立点数据敏感。

- K-means++算法可解决第2，3条缺点

### K-means++

k-means++算法选择初始聚类中心的基本原则是：初始的聚类中心之间的相互距离要尽可能的远。

步骤一：随机选取一个样本作为第一个聚类中心；
步骤二：计算每个样本与当前已有聚类中心的最短距离(即与最近一个聚类中心的距离)，这个值越大，表示被选取作为聚类中心的概率较大；最后，用轮盘法(依据概率大小来进行抽选)选出下一个聚类中心；
步骤三：重复步骤二，直到选出K个聚类中心。选出初始点后，就继续使用标准的K-means算法了。

### SPSS操作

分析 - 分类 - K-均值聚类分析(默认即为K-means++)

保存：全选

选项：勾选1，3

## 系统(层次)聚类算法

通过计算两类数据点间的距离，对最为接近的两类数据点进行组合，并反复迭代这一过程，直到将所有数据点合成一类，并生成聚类谱系图。

### 流程

一、将每个对象看作一类，计算两两之间的最小距离；
二、将距离最小的两个类合并成一个新类；
三、重新计算新类与所有类之间的距离；
四、重复二三两步，直到所有类最后合并成一类。

### SPSS操作

- 分析 - 分类 - 系统聚类 - 将分类指标放入变量中，将分类样本放入个案标注依据

  图：勾选谱系图

  方法：若数据量纲不同则“标准化”选择Z得分

- 在通过下面方法确定K后重新聚类一次，这次“保存”选择“单个解”并输入聚类数

- 第二次聚类结束后画图

### 聚合系数折线图 (用图形估计聚类数量)

**论文中是要解释聚类个数的原因和每类分别代表的含义**

- 聚合系数折线图：横坐标未聚类的类别数K，纵坐标未聚合系数J；
  聚合系数J也称为所有类的总畸变程度。

- 聚合系数折线图画法

  1. 数据处理

     把SPSS生成报告中《集中计划》表格的系数列数据粘贴到Excel表格中，并按照降序排好。

  2. 插入 - 推荐的图标 - 散点图

- 估计K值：肘部法则

  通过看聚合系数折线图的突变点大致估计K指，也就是找由陡峭到平缓的点 (建议K不超过5)

  例：

  根据图来进行解释：
  (1)根据聚合系数折线图可知，当类别数为5时，折线的下降趋势趋缓，故可将类别数设定为5。
  (2)从图中可以看出， K值从1到5时，畸变程度变化最大。超过5以后，畸变程度变化显著降低。因此肘部就是 K=5，故可将类别数设定为5。(当然，K=3也可以解释)

### 画图

只有指标个数为2或3才能作图

见10-2课程

## DBSCAN算法

具有噪声的基于密度的聚类方法(上两种算法是基于距离的)

### 优缺点

- 优点
  1. 基于密度定义，能处理任意形状和大小的簇；
  2. 可在聚类的同时发现异常点；
  3. 与K-means比较起来，不需要输入聚类个数K值
- 缺点
  1. 对epsilon和MinPts非常敏感，确定这两个参数困难；
  2. 当聚类的密度不均匀时，聚类距离相差很大时，聚类质量差；
  3. 数据量大时计算复杂。

